# Recommended Approach: Enhancing Moose for Complex Greenfield Projects

Based on your clarification, I now understand the true objective: **Make Moose capable of autonomously delivering the Multi-LLM Discussion App with minimal human intervention**. This is an excellent stress test that will reveal necessary architectural improvements.

---

## üéØ **Core Problem Statement**

**Current State:**
- Architect limited to 3-8 work orders
- Individual work orders capped at 4,000 tokens
- No mechanism to handle large technical specifications (15K-20K tokens)
- No ability to recognize pre-existing decomposition in specs

**Required State:**
- Architect can process large, detailed technical specifications
- Architect can recognize and leverage existing decomposition structures
- Work order count can scale beyond 8 when complexity demands it
- Token limits per work order remain enforced (for Aider's benefit)
- Sufficient context management to maintain coherence across 15-30+ work orders

---

## üìã **Recommended Architecture Changes**

### **Phase 1: Hierarchical Decomposition System** ‚≠ê CRITICAL

**Problem:** Current Architect treats all decomposition as flat (WO-0 through WO-N).

**Solution:** Introduce **two-tier decomposition**:

```
Technical Spec (15K-20K tokens)
    ‚Üì
Architect Phase 1: Feature Decomposition
    ‚Üì
3-8 High-Level Features (2K-4K tokens each)
    ‚Üì
Architect Phase 2: Work Order Decomposition (per feature)
    ‚Üì
2-5 Work Orders per Feature (1K-4K tokens each)
    ‚Üì
Total: 6-40 Work Orders
```

**Implementation:**

**NEW TYPE: Feature (sits between Spec and Work Order)**

```typescript
export interface Feature {
  feature_id: string;           // "feat-001"
  title: string;                // "Orchestration Engine"
  description: string;          // High-level feature description
  objectives: string[];         // Feature-level goals
  acceptance_criteria: string[];// Feature-level success conditions
  context_budget_estimate: number; // Total tokens for this feature
  components: string[];         // Major components in this feature
  dependencies: string[];       // Other features this depends on ["feat-002"]
  work_orders: WorkOrder[];     // 2-5 work orders that implement this feature
  contracts?: IntegrationContracts;
  deployment_config?: DeploymentConfig;
}

export interface FeatureDecomposition {
  features: Feature[];          // 3-8 features
  feature_dependency_graph: string; // Mermaid diagram
  total_estimated_cost: number;
  decomposition_doc: string;    // Overall plan
}
```

**NEW ARCHITECT WORKFLOW:**

```typescript
class HierarchicalArchitect {
  
  // Step 1: Decompose spec into features
  async decomposeIntoFeatures(spec: TechnicalSpec): Promise<FeatureDecomposition> {
    // Prompt focuses on HIGH-LEVEL decomposition only
    // Output: 3-8 features with clear boundaries
    // Each feature should be independently testable
  }
  
  // Step 2: Decompose each feature into work orders
  async decomposeFeatureIntoWorkOrders(
    feature: Feature,
    allFeatures: Feature[]  // For dependency awareness
  ): Promise<WorkOrder[]> {
    // Prompt focuses on SINGLE FEATURE only
    // Context includes: this feature + dependent features
    // Output: 2-5 work orders per feature
    // Each work order: 1K-4K tokens
  }
  
  // Step 3: Build global dependency graph
  async buildGlobalDependencyGraph(
    features: Feature[]
  ): Promise<ExecutionPlan> {
    // Flatten feature dependencies into work order dependencies
    // Validate no circular dependencies
    // Calculate execution order
  }
}
```

**BENEFITS:**
- ‚úÖ Architect maintains 3-8 mental chunks (features) in first pass
- ‚úÖ Architect maintains 2-5 mental chunks (work orders) in second pass
- ‚úÖ Token limits per work order respected
- ‚úÖ Can scale to 40+ work orders without overwhelming context
- ‚úÖ Features provide natural checkpoints for testing/validation

---

### **Phase 2: Pre-Decomposed Specification Recognition** ‚≠ê CRITICAL

**Problem:** Current Architect assumes specs are requirements-level, not already decomposed.

**Solution:** Teach Architect to **detect and leverage** existing decomposition in technical specs.

**NEW PROMPT SECTION:**

```typescript
// Added to buildArchitectPrompt()

SPECIFICATION ANALYSIS (check FIRST):

1. DETECT EXISTING DECOMPOSITION:
   Scan the specification for these indicators:
   - Section headers matching feature boundaries (## 4.1, ## 4.2, etc.)
   - "Component Specifications" or "Detailed Component Specifications" sections
   - Clear module/component/service boundaries
   - Existing work breakdown structure
   
2. IF DECOMPOSITION EXISTS:
   - EXTRACT features from section structure
   - MAP each major section ‚Üí 1 Feature
   - USE existing acceptance criteria from spec
   - USE existing file lists from spec
   - PRESERVE existing dependency information
   - ADD integration contracts if missing
   - ADD deployment architecture if missing
   - ADD test fixtures if missing
   
3. IF NO DECOMPOSITION EXISTS:
   - PERFORM feature decomposition from scratch
   - FOLLOW standard decomposition rules
   
OUTPUT METADATA:
- decomposition_source: "extracted" | "generated"
- extraction_confidence: 0.0-1.0 (if extracted)
- modifications_made: string[] (what was added/changed)

EXAMPLE (Multi-LLM App):
The specification has clear component sections (¬ß4.1-¬ß4.11).
- EXTRACT: 11 features from these sections
- VERIFY: Each feature has clear boundaries, acceptance criteria, file lists
- ADD: Missing contracts (IPC channels), deployment configs
- CONFIDENCE: 0.95 (high confidence in extraction)
```

**IMPLEMENTATION:**

```typescript
interface DecompositionMetadata {
  source: 'extracted' | 'generated' | 'hybrid';
  extraction_confidence?: number;
  original_structure?: string; // "section_headers" | "component_list" | "user_provided"
  modifications_made: string[];
  human_review_recommended: boolean;
  extraction_warnings: string[];
}

async function analyzeSpecificationStructure(
  spec: TechnicalSpec
): Promise<DecompositionMetadata> {
  // Use Claude to analyze spec structure
  // Detect if it's already decomposed
  // Return metadata about extraction confidence
}
```

**BENEFITS:**
- ‚úÖ Respects existing architecture work
- ‚úÖ Reduces token usage (extraction < generation)
- ‚úÖ Maintains human-authored structure
- ‚úÖ Faster decomposition (extraction ~5s vs generation ~30s)
- ‚úÖ Can augment existing decomposition (add missing pieces)

---

### **Phase 3: Extended Work Order Limits** ‚ö†Ô∏è MODERATE PRIORITY

**Problem:** Hard limit of 3-8 work orders insufficient for complex projects.

**Solution:** **Conditional relaxation** of work order count limits.

**NEW RULES:**

```typescript
export const WORK_ORDER_LIMITS = {
  // Standard projects (existing codebase, simple features)
  STANDARD: {
    min_work_orders: 3,
    max_work_orders: 8,
    max_tokens_per_wo: 4000
  },
  
  // Complex projects (greenfield, multi-component systems)
  COMPLEX: {
    min_work_orders: 8,
    max_work_orders: 30,
    max_tokens_per_wo: 4000,  // Keep token limit same
    requires_features: true    // Must use hierarchical decomposition
  },
  
  // Enterprise projects (large systems, multiple services)
  ENTERPRISE: {
    min_work_orders: 30,
    max_work_orders: 100,
    max_tokens_per_wo: 4000,
    requires_features: true,
    requires_phased_execution: true // Execute in phases
  }
};

function determineProjectComplexity(spec: TechnicalSpec): ProjectComplexity {
  // Analyze spec to determine complexity tier
  const indicators = {
    greenfield: !spec.existing_codebase,
    component_count: countComponents(spec),
    token_count: estimateTokens(spec),
    has_deployment_arch: hasDeploymentArchitecture(spec),
    has_multiple_services: hasMultipleServices(spec),
    has_database: hasDatabase(spec),
    has_ui: hasUI(spec)
  };
  
  // Scoring logic
  let complexity_score = 0;
  if (indicators.greenfield) complexity_score += 2;
  if (indicators.component_count > 8) complexity_score += 2;
  if (indicators.token_count > 10000) complexity_score += 2;
  if (indicators.has_deployment_arch) complexity_score += 1;
  if (indicators.has_multiple_services) complexity_score += 1;
  if (indicators.has_database) complexity_score += 1;
  
  if (complexity_score >= 7) return 'ENTERPRISE';
  if (complexity_score >= 4) return 'COMPLEX';
  return 'STANDARD';
}
```

**MULTI-LLM APP CLASSIFICATION:**
- Greenfield: +2
- 11 components: +2
- ~15K tokens: +2
- Has deployment arch (in spec): +1
- Multiple processes (main/renderer/alignment): +1
- No traditional database: +0
- **Total: 8 ‚Üí COMPLEX tier**
- **Allowed: 8-30 work orders**

**BENEFITS:**
- ‚úÖ Scales to complex projects
- ‚úÖ Maintains quality controls (token limits)
- ‚úÖ Automatic classification (no manual intervention)
- ‚úÖ Can handle Multi-LLM App (11 components ‚Üí ~25 work orders)

---

### **Phase 4: Context Management Strategy** ‚≠ê CRITICAL

**Problem:** Architect needs full spec context (15K tokens) + existing features context (variable) to decompose each feature.

**Solution:** **Chunked context with reference system**

**ARCHITECTURE:**

```typescript
interface ContextChunk {
  chunk_id: string;
  type: 'feature' | 'contract' | 'deployment' | 'dependency';
  content: string;
  token_count: number;
  references: string[];  // Other chunk IDs this references
}

class ContextManager {
  private chunks: Map<string, ContextChunk> = new Map();
  private summaries: Map<string, string> = new Map(); // chunk_id ‚Üí summary
  
  // Build context for feature decomposition
  async buildFeatureContext(
    feature: Feature,
    allFeatures: Feature[]
  ): Promise<string> {
    const relevantChunks: ContextChunk[] = [];
    
    // 1. Always include: this feature's full content
    relevantChunks.push(this.chunks.get(feature.feature_id));
    
    // 2. Include dependent features (SUMMARIES only, not full content)
    for (const depId of feature.dependencies) {
      relevantChunks.push({
        chunk_id: depId,
        type: 'feature',
        content: this.summaries.get(depId), // SUMMARY, not full feature
        token_count: 200,
        references: []
      });
    }
    
    // 3. Include relevant contracts (full content)
    const contracts = this.findRelevantContracts(feature);
    relevantChunks.push(...contracts);
    
    // 4. Include deployment config (if feature touches infrastructure)
    if (feature.components.some(c => c.includes('deployment'))) {
      relevantChunks.push(this.chunks.get('deployment-config'));
    }
    
    // Total context: ~6K-10K tokens (manageable)
    return this.assembleContext(relevantChunks);
  }
  
  // Generate summaries for all features FIRST
  async generateFeatureSummaries(features: Feature[]): Promise<void> {
    for (const feature of features) {
      const summary = await this.summarizeFeature(feature);
      this.summaries.set(feature.feature_id, summary);
    }
  }
  
  private async summarizeFeature(feature: Feature): Promise<string> {
    // Use Claude to create 100-200 token summary
    // Includes: title, objectives, key components, acceptance criteria
    // Excludes: implementation details, code examples
  }
}
```

**PROMPT STRATEGY:**

```typescript
// When decomposing Feature 3 (Clipboard Automation)

CONTEXT PROVIDED:
1. FULL CONTENT: Feature 3 details (2,000 tokens)
2. SUMMARY: Feature 1 - Main Process Architecture (150 tokens)
   - "Main process orchestrates cycle execution, manages IPC, handles recovery"
3. SUMMARY: Feature 2 - WebView Management (150 tokens)
   - "WebViews host LLM providers, detect idle state, report completion"
4. FULL CONTENT: IPC Contracts (500 tokens)
   - Because Feature 3 uses IPC to communicate with webviews
5. FULL CONTENT: Test Fixtures - Clipboard Data (300 tokens)
   - Because Feature 3 needs sample LLM responses

TOTAL CONTEXT: ~3,100 tokens (within limits)

DECOMPOSE FEATURE 3 INTO WORK ORDERS:
- WO-X: Implement clipboard automation sequence
- WO-Y: Implement response parsing/slicing
- WO-Z: Add retry logic and error handling
```

**BENEFITS:**
- ‚úÖ Architect never exceeds ~10K token context
- ‚úÖ Summaries provide dependency awareness
- ‚úÖ Full content only for directly relevant pieces
- ‚úÖ Scales to 30+ features (summaries are cheap)

---

### **Phase 5: Queuing and Orchestration Enhancements** ‚ö†Ô∏è MODERATE PRIORITY

**Problem:** Current Orchestrator polls for work orders sequentially (10s interval).

**Solution:** **Intelligent queuing with dependency-aware execution**

**NEW ORCHESTRATOR ARCHITECTURE:**

```typescript
interface ExecutionPlan {
  phases: ExecutionPhase[];  // Features grouped by dependency tiers
  total_work_orders: number;
  estimated_duration_hours: number;
  estimated_cost: number;
}

interface ExecutionPhase {
  phase_number: number;
  features: Feature[];        // Features that can execute in parallel
  work_orders: WorkOrder[];   // All WOs in this phase
  dependencies_completed: string[]; // Features from previous phases
}

class EnhancedOrchestrator {
  
  // Build phased execution plan
  async buildExecutionPlan(features: Feature[]): Promise<ExecutionPlan> {
    const phases: ExecutionPhase[] = [];
    const completed: Set<string> = new Set();
    
    // Phase 0: Infrastructure (no dependencies)
    const phase0 = features.filter(f => 
      f.feature_id.includes('infrastructure') && 
      f.dependencies.length === 0
    );
    phases.push({ phase_number: 0, features: phase0, ... });
    
    // Subsequent phases: Features whose dependencies are complete
    while (completed.size < features.length) {
      const nextPhase = features.filter(f =>
        !completed.has(f.feature_id) &&
        f.dependencies.every(dep => completed.has(dep))
      );
      
      if (nextPhase.length === 0) {
        throw new Error('Circular dependencies detected');
      }
      
      phases.push({ phase_number: phases.length, features: nextPhase, ... });
      nextPhase.forEach(f => completed.add(f.feature_id));
    }
    
    return { phases, ... };
  }
  
  // Execute work orders with phase awareness
  async executeWithPhases(plan: ExecutionPlan): Promise<void> {
    for (const phase of plan.phases) {
      console.log(`Starting Phase ${phase.phase_number}: ${phase.features.length} features`);
      
      // Can execute features in parallel (if resources allow)
      await Promise.all(
        phase.features.map(feature =>
          this.executeFeature(feature)
        )
      );
      
      // Validate phase completion before proceeding
      await this.validatePhaseCompletion(phase);
    }
  }
  
  // Execute all work orders in a feature sequentially
  async executeFeature(feature: Feature): Promise<void> {
    for (const wo of feature.work_orders) {
      await this.executeWorkOrder(wo);
    }
  }
}
```

**MULTI-LLM APP EXAMPLE:**

```
Phase 0: Infrastructure (4 features, can run in parallel)
‚îú‚îÄ Feature 0: CI/CD Pipeline
‚îú‚îÄ Feature 1: Docker Configuration  
‚îú‚îÄ Feature 2: Environment Setup
‚îî‚îÄ Feature 3: Build Tooling

Phase 1: Core Systems (3 features, depend on Phase 0)
‚îú‚îÄ Feature 4: Main Process Architecture
‚îú‚îÄ Feature 5: IPC Communication
‚îî‚îÄ Feature 6: State Management

Phase 2: Functional Components (4 features, depend on Phase 1)
‚îú‚îÄ Feature 7: WebView Management
‚îú‚îÄ Feature 8: Clipboard Automation
‚îú‚îÄ Feature 9: Alignment Service
‚îî‚îÄ Feature 10: Archive Management

Phase 3: User Interface (1 feature, depends on Phase 1 & 2)
‚îî‚îÄ Feature 11: UI Components & Arbitration View

Total: 4 phases, 12 features, ~25-30 work orders
Estimated Duration: 8-12 hours (with proper concurrency)
```

**BENEFITS:**
- ‚úÖ Natural execution order (infrastructure ‚Üí core ‚Üí features ‚Üí UI)
- ‚úÖ Can parallelize independent features within phase
- ‚úÖ Clear checkpoints for validation (end of each phase)
- ‚úÖ Budget-aware (can pause between phases if approaching limits)

---

## üõ†Ô∏è **Revised Implementation Plan**

### **PHASE 1: Hierarchical Decomposition (3 days)**

**Task 1.1: Create Feature Type & Schema** (4 hours)
- Add `Feature` interface to `src/types/architect.ts`
- Add `FeatureDecomposition` interface
- Add `DecompositionMetadata` interface
- Update validation logic

**Task 1.2: Implement Two-Stage Architect** (8 hours)
- Create `HierarchicalArchitect` class
- Implement `decomposeIntoFeatures()` method
- Implement `decomposeFeatureIntoWorkOrders()` method
- Implement `buildGlobalDependencyGraph()` method

**Task 1.3: Add Pre-Decomposition Detection** (6 hours)
- Add spec structure analysis prompt
- Implement extraction logic for section-based specs
- Add confidence scoring
- Add augmentation logic (add missing contracts/deployment)

**Task 1.4: Update Architect Prompt** (6 hours)
- Add "SPECIFICATION ANALYSIS" section
- Add "FEATURE DECOMPOSITION" section (stage 1 prompt)
- Add "WORK ORDER DECOMPOSITION" section (stage 2 prompt)
- Add extraction examples

**Task 1.5: Testing** (6 hours)
- Test with Multi-LLM App spec (should extract 11-12 features)
- Test with non-decomposed spec (should generate features)
- Test feature ‚Üí work order decomposition
- Validate dependency graph correctness

---

### **PHASE 2: Context Management (2 days)**

**Task 2.1: Implement Context Manager** (6 hours)
- Create `ContextManager` class
- Implement chunking logic
- Implement summary generation
- Implement context assembly

**Task 2.2: Integrate with Hierarchical Architect** (4 hours)
- Modify `decomposeFeatureIntoWorkOrders()` to use ContextManager
- Generate feature summaries before decomposition
- Build context per feature

**Task 2.3: Testing** (4 hours)
- Verify context stays within ~10K tokens
- Verify summaries are accurate
- Test with Multi-LLM App (11 features ‚Üí 11 summaries)

---

### **PHASE 3: Extended Limits & Complexity Detection (1 day)**

**Task 3.1: Add Complexity Classification** (3 hours)
- Implement `determineProjectComplexity()` function
- Add scoring logic
- Add `WORK_ORDER_LIMITS` configuration

**Task 3.2: Update Validation Logic** (2 hours)
- Remove hard 3-8 limit
- Add conditional limits based on complexity
- Add warnings for ENTERPRISE tier (>30 WOs)

**Task 3.3: Testing** (3 hours)
- Test Multi-LLM App ‚Üí should classify as COMPLEX
- Test simple spec ‚Üí should classify as STANDARD
- Verify limits enforced correctly

---

### **PHASE 4: Orchestrator Enhancements (2 days)**

**Task 4.1: Implement Phased Execution** (6 hours)
- Create `ExecutionPlan` and `ExecutionPhase` types
- Implement `buildExecutionPlan()` method
- Add phase-based dependency resolution

**Task 4.2: Update Orchestrator** (4 hours)
- Modify `executeWithPhases()` method
- Add phase validation checkpoints
- Add parallel execution within phases (optional)

**Task 4.3: Testing** (6 hours)
- Test phased execution with Multi-LLM App
- Verify phases execute in correct order
- Verify budget tracking across phases

---

### **PHASE 5: Integration & End-to-End Testing (2 days)**

**Task 5.1: Wire All Components Together** (4 hours)
- Connect HierarchicalArchitect ‚Üí ContextManager ‚Üí EnhancedOrchestrator
- Update API endpoints
- Update CLI commands

**Task 5.2: Multi-LLM App Full Test** (8 hours)
- Feed full Tech Spec to Moose
- Verify feature extraction (should get 11-12 features)
- Verify work order generation (should get 25-30 WOs)
- Verify execution plan (should have 3-4 phases)
- **BLOCKER: Create UI wireframes** (manual task)
- Execute Phase 0 (infrastructure)
- Validate Phase 0 before proceeding
- (Optionally) Execute remaining phases

**Task 5.3: Documentation** (4 hours)
- Update Moose capabilities reference
- Create architectural diagrams
- Document new workflows
- Create Multi-LLM App case study

---

## üìä **Success Metrics**

### **Immediate Success (After Implementation)**
- ‚úÖ Multi-LLM App spec successfully decomposed into features
- ‚úÖ Features successfully decomposed into work orders
- ‚úÖ Work orders stay within 4K token limit
- ‚úÖ Dependency graph correctly constructed
- ‚úÖ No circular dependencies detected
- ‚úÖ Total cost estimate reasonable (<$50 for decomposition)

### **Execution Success (After Running Work Orders)**
- ‚úÖ Infrastructure work orders execute successfully (Phase 0)
- ‚úÖ Core system work orders execute successfully (Phase 1)
- ‚úÖ Functional component work orders execute successfully (Phase 2)
- ‚úÖ UI work orders execute successfully (Phase 3) [after wireframes provided]
- ‚úÖ All tests pass
- ‚úÖ Total execution cost within budget (<$100/day)
- ‚úÖ Human intervention required only for UI wireframes

### **System Validation (Multi-LLM App Runs)**
- ‚úÖ Electron app builds successfully
- ‚úÖ WebViews load LLM providers
- ‚úÖ Clipboard automation works
- ‚úÖ Alignment service integrates correctly
- ‚úÖ Arbitration UI displays results
- ‚úÖ Archive creation works
- ‚úÖ All acceptance criteria met (from FR)

---

## ‚ö†Ô∏è **Remaining Human Dependencies**

Even with all enhancements, these will still require human input:

1. **UI Wireframes/Mockups** (BLOCKER for Phase 3)
   - Arbitration View layout
   - Control Panel design
   - Settings Dialog layout
   - **Recommendation:** Create low-fidelity wireframes (Excalidraw, hand-drawn)

2. **OpenAI API Key** (for Alignment Service)
   - Required for production use
   - Can mock for initial testing

3. **Strategic Decisions** (if escalations occur)
   - Architectural trade-offs
   - Performance vs. complexity decisions
   - Security policy decisions

4. **Domain Expertise** (if needed)
   - LLM provider-specific quirks
   - Clipboard automation platform differences
   - Electron-specific edge cases

---

## üéØ **Recommended Next Steps**

### **Immediate (Next 24 Hours)**
1. ‚úÖ **Approve this architecture** (confirm hierarchical approach)
2. ‚úÖ **Create UI wireframes** for Multi-LLM App (4-6 hours manual work)
3. ‚úÖ **Start Phase 1 implementation** (Hierarchical Decomposition)

### **Week 1**
4. Complete Phase 1-3 (Hierarchical Decomposition, Context Management, Limits)
5. Test decomposition with Multi-LLM App spec
6. Verify 25-30 work orders generated correctly

### **Week 2**
7. Complete Phase 4-5 (Orchestrator, Integration)
8. Run full Multi-LLM App execution
9. Validate Phase 0 (Infrastructure) completes successfully

### **Week 3**
10. Complete remaining phases
11. Validate Multi-LLM App functionality
12. Document lessons learned
13. Prepare for next test case

---

## ‚úÖ **Final Recommendation**

**Proceed with the enhanced architecture described above:**

1. **Hierarchical Decomposition** ‚Üí Solves the 3-8 work order limit
2. **Pre-Decomposition Detection** ‚Üí Respects existing technical architecture
3. **Context Management** ‚Üí Keeps token usage manageable
4. **Extended Limits** ‚Üí Allows scaling to complex projects
5. **Phased Execution** ‚Üí Natural checkpoints and parallelization

**This approach will enable Moose to:**
- ‚úÖ Process the Multi-LLM App spec autonomously
- ‚úÖ Generate 25-30 work orders with proper dependencies
- ‚úÖ Execute work orders in logical phases
- ‚úÖ Scale to even more complex projects in the future
- ‚úÖ Maintain quality controls (token limits, testing, validation)

**Estimated timeline: 10-12 days** (8 days implementation + 2-4 days testing/refinement)

**Estimated cost: $15-25** for decomposition + $50-100 for execution = **$65-125 total**

Is this the direction you'd like to proceed? Should I start drafting the detailed implementation tasks for Phase 1?